{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"train\"\n",
    "test_dir = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True, validation_split=0.2)\n",
    "\n",
    "training_data = dataGenerator.flow_from_directory(train_dir, batch_size=64, target_size=(48, 48), shuffle=True, color_mode='grayscale', class_mode='categorical', subset='training')\n",
    "validation_set = dataGenerator.flow_from_directory(train_dir, batch_size=64, target_size=(48, 48), shuffle=True, color_mode='grayscale', class_mode='categorical', subset='validation')\n",
    "\n",
    "testDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "test_data = testDataGenerator.flow_from_directory(test_dir, batch_size=64, target_size=(48, 48), shuffle=True, color_mode='grayscale', class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    weight_decay = 1e-4\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay), input_shape=(48, 48, 1)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (4, 4), padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(128, (4, 4), padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(128, (4, 4), padding='same', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"linear\"))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dense(7, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0003), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = [tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', verbose = 1, restore_best_weights=True, mode=\"max\",patience = 10),\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='final_model_weights.hdf5',\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode=\"max\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.5183 - accuracy: 0.4279\n",
      "Epoch 1: val_accuracy improved from 0.29933 to 0.44154, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 221s 618ms/step - loss: 1.5183 - accuracy: 0.4279 - val_loss: 1.4728 - val_accuracy: 0.4415\n",
      "Epoch 2/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.4002 - accuracy: 0.4791\n",
      "Epoch 2: val_accuracy improved from 0.44154 to 0.50579, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 218s 610ms/step - loss: 1.4002 - accuracy: 0.4791 - val_loss: 1.3471 - val_accuracy: 0.5058\n",
      "Epoch 3/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.3139 - accuracy: 0.5151\n",
      "Epoch 3: val_accuracy did not improve from 0.50579\n",
      "358/358 [==============================] - 223s 622ms/step - loss: 1.3139 - accuracy: 0.5151 - val_loss: 1.4182 - val_accuracy: 0.4910\n",
      "Epoch 4/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.2577 - accuracy: 0.5354\n",
      "Epoch 4: val_accuracy improved from 0.50579 to 0.51457, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 231s 646ms/step - loss: 1.2577 - accuracy: 0.5354 - val_loss: 1.2984 - val_accuracy: 0.5146\n",
      "Epoch 5/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.2045 - accuracy: 0.5620\n",
      "Epoch 5: val_accuracy improved from 0.51457 to 0.55811, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 235s 656ms/step - loss: 1.2045 - accuracy: 0.5620 - val_loss: 1.1998 - val_accuracy: 0.5581\n",
      "Epoch 6/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.1630 - accuracy: 0.5796\n",
      "Epoch 6: val_accuracy improved from 0.55811 to 0.56917, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 224s 626ms/step - loss: 1.1630 - accuracy: 0.5796 - val_loss: 1.1889 - val_accuracy: 0.5692\n",
      "Epoch 7/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.1237 - accuracy: 0.5944\n",
      "Epoch 7: val_accuracy did not improve from 0.56917\n",
      "358/358 [==============================] - 223s 623ms/step - loss: 1.1237 - accuracy: 0.5944 - val_loss: 1.3419 - val_accuracy: 0.4998\n",
      "Epoch 8/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.0990 - accuracy: 0.6009\n",
      "Epoch 8: val_accuracy improved from 0.56917 to 0.57584, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 211s 589ms/step - loss: 1.0990 - accuracy: 0.6009 - val_loss: 1.1521 - val_accuracy: 0.5758\n",
      "Epoch 9/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.0653 - accuracy: 0.6175\n",
      "Epoch 9: val_accuracy improved from 0.57584 to 0.58690, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 209s 584ms/step - loss: 1.0653 - accuracy: 0.6175 - val_loss: 1.1425 - val_accuracy: 0.5869\n",
      "Epoch 10/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.0369 - accuracy: 0.6281\n",
      "Epoch 10: val_accuracy did not improve from 0.58690\n",
      "358/358 [==============================] - 208s 581ms/step - loss: 1.0369 - accuracy: 0.6281 - val_loss: 1.1722 - val_accuracy: 0.5758\n",
      "Epoch 11/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.6410\n",
      "Epoch 11: val_accuracy did not improve from 0.58690\n",
      "358/358 [==============================] - 213s 595ms/step - loss: 1.0097 - accuracy: 0.6410 - val_loss: 1.1796 - val_accuracy: 0.5823\n",
      "Epoch 12/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.9879 - accuracy: 0.6484\n",
      "Epoch 12: val_accuracy improved from 0.58690 to 0.59112, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 564ms/step - loss: 0.9879 - accuracy: 0.6484 - val_loss: 1.1349 - val_accuracy: 0.5911\n",
      "Epoch 13/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.9580 - accuracy: 0.6618\n",
      "Epoch 13: val_accuracy improved from 0.59112 to 0.60270, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 564ms/step - loss: 0.9580 - accuracy: 0.6618 - val_loss: 1.1272 - val_accuracy: 0.6027\n",
      "Epoch 14/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.6711\n",
      "Epoch 14: val_accuracy improved from 0.60270 to 0.60341, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 200s 560ms/step - loss: 0.9404 - accuracy: 0.6711 - val_loss: 1.1269 - val_accuracy: 0.6034\n",
      "Epoch 15/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.9155 - accuracy: 0.6811\n",
      "Epoch 15: val_accuracy improved from 0.60341 to 0.61254, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 200s 560ms/step - loss: 0.9155 - accuracy: 0.6811 - val_loss: 1.1186 - val_accuracy: 0.6125\n",
      "Epoch 16/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.8858 - accuracy: 0.6944\n",
      "Epoch 16: val_accuracy did not improve from 0.61254\n",
      "358/358 [==============================] - 200s 558ms/step - loss: 0.8858 - accuracy: 0.6944 - val_loss: 1.1405 - val_accuracy: 0.6081\n",
      "Epoch 17/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.8640 - accuracy: 0.7018\n",
      "Epoch 17: val_accuracy did not improve from 0.61254\n",
      "358/358 [==============================] - 212s 591ms/step - loss: 0.8640 - accuracy: 0.7018 - val_loss: 1.1462 - val_accuracy: 0.6045\n",
      "Epoch 18/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.7128\n",
      "Epoch 18: val_accuracy did not improve from 0.61254\n",
      "358/358 [==============================] - 206s 575ms/step - loss: 0.8404 - accuracy: 0.7128 - val_loss: 1.1562 - val_accuracy: 0.6071\n",
      "Epoch 19/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.8267 - accuracy: 0.7171\n",
      "Epoch 19: val_accuracy improved from 0.61254 to 0.62202, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 564ms/step - loss: 0.8267 - accuracy: 0.7171 - val_loss: 1.1218 - val_accuracy: 0.6220\n",
      "Epoch 20/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7982 - accuracy: 0.7283\n",
      "Epoch 20: val_accuracy did not improve from 0.62202\n",
      "358/358 [==============================] - 1428s 4s/step - loss: 0.7982 - accuracy: 0.7283 - val_loss: 1.1542 - val_accuracy: 0.6175\n",
      "Epoch 21/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7805 - accuracy: 0.7365\n",
      "Epoch 21: val_accuracy did not improve from 0.62202\n",
      "358/358 [==============================] - 206s 576ms/step - loss: 0.7805 - accuracy: 0.7365 - val_loss: 1.2151 - val_accuracy: 0.5992\n",
      "Epoch 22/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7617 - accuracy: 0.7441\n",
      "Epoch 22: val_accuracy did not improve from 0.62202\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.7617 - accuracy: 0.7441 - val_loss: 1.1706 - val_accuracy: 0.6194\n",
      "Epoch 23/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.7514\n",
      "Epoch 23: val_accuracy improved from 0.62202 to 0.62377, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.7470 - accuracy: 0.7514 - val_loss: 1.1801 - val_accuracy: 0.6238\n",
      "Epoch 24/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.7673\n",
      "Epoch 24: val_accuracy improved from 0.62377 to 0.62728, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.7140 - accuracy: 0.7673 - val_loss: 1.1682 - val_accuracy: 0.6273\n",
      "Epoch 25/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.7083 - accuracy: 0.7710\n",
      "Epoch 25: val_accuracy did not improve from 0.62728\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.7083 - accuracy: 0.7710 - val_loss: 1.2832 - val_accuracy: 0.5967\n",
      "Epoch 26/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.7756\n",
      "Epoch 26: val_accuracy did not improve from 0.62728\n",
      "358/358 [==============================] - 202s 564ms/step - loss: 0.6909 - accuracy: 0.7756 - val_loss: 1.1999 - val_accuracy: 0.6257\n",
      "Epoch 27/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.7832\n",
      "Epoch 27: val_accuracy improved from 0.62728 to 0.62886, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 204s 569ms/step - loss: 0.6705 - accuracy: 0.7832 - val_loss: 1.2308 - val_accuracy: 0.6289\n",
      "Epoch 28/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.7883\n",
      "Epoch 28: val_accuracy improved from 0.62886 to 0.63237, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.6569 - accuracy: 0.7883 - val_loss: 1.2344 - val_accuracy: 0.6324\n",
      "Epoch 29/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.7985\n",
      "Epoch 29: val_accuracy did not improve from 0.63237\n",
      "358/358 [==============================] - 209s 583ms/step - loss: 0.6364 - accuracy: 0.7985 - val_loss: 1.2543 - val_accuracy: 0.6248\n",
      "Epoch 30/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.7992\n",
      "Epoch 30: val_accuracy improved from 0.63237 to 0.63588, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 205s 571ms/step - loss: 0.6310 - accuracy: 0.7992 - val_loss: 1.2552 - val_accuracy: 0.6359\n",
      "Epoch 31/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.8092\n",
      "Epoch 31: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.6033 - accuracy: 0.8092 - val_loss: 1.3593 - val_accuracy: 0.5994\n",
      "Epoch 32/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.8111\n",
      "Epoch 32: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.6045 - accuracy: 0.8111 - val_loss: 1.2919 - val_accuracy: 0.6297\n",
      "Epoch 33/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.8214\n",
      "Epoch 33: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 566ms/step - loss: 0.5830 - accuracy: 0.8214 - val_loss: 1.3473 - val_accuracy: 0.6162\n",
      "Epoch 34/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.8204\n",
      "Epoch 34: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 564ms/step - loss: 0.5797 - accuracy: 0.8204 - val_loss: 1.3117 - val_accuracy: 0.6248\n",
      "Epoch 35/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8292\n",
      "Epoch 35: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 565ms/step - loss: 0.5593 - accuracy: 0.8292 - val_loss: 1.5139 - val_accuracy: 0.5679\n",
      "Epoch 36/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.8323\n",
      "Epoch 36: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 203s 567ms/step - loss: 0.5616 - accuracy: 0.8323 - val_loss: 1.3178 - val_accuracy: 0.6275\n",
      "Epoch 37/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.8365\n",
      "Epoch 37: val_accuracy did not improve from 0.63588\n",
      "358/358 [==============================] - 202s 563ms/step - loss: 0.5391 - accuracy: 0.8365 - val_loss: 1.3570 - val_accuracy: 0.6322\n",
      "Epoch 38/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8395\n",
      "Epoch 38: val_accuracy improved from 0.63588 to 0.63799, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 202s 563ms/step - loss: 0.5369 - accuracy: 0.8395 - val_loss: 1.3351 - val_accuracy: 0.6380\n",
      "Epoch 39/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8454\n",
      "Epoch 39: val_accuracy did not improve from 0.63799\n",
      "358/358 [==============================] - 203s 566ms/step - loss: 0.5249 - accuracy: 0.8454 - val_loss: 1.3762 - val_accuracy: 0.6334\n",
      "Epoch 40/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5159 - accuracy: 0.8489\n",
      "Epoch 40: val_accuracy did not improve from 0.63799\n",
      "358/358 [==============================] - 487s 1s/step - loss: 0.5159 - accuracy: 0.8489 - val_loss: 1.3676 - val_accuracy: 0.6273\n",
      "Epoch 41/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8543\n",
      "Epoch 41: val_accuracy did not improve from 0.63799\n",
      "358/358 [==============================] - 379s 1s/step - loss: 0.5051 - accuracy: 0.8543 - val_loss: 1.3762 - val_accuracy: 0.6297\n",
      "Epoch 42/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.8586\n",
      "Epoch 42: val_accuracy did not improve from 0.63799\n",
      "358/358 [==============================] - 209s 582ms/step - loss: 0.4975 - accuracy: 0.8586 - val_loss: 1.4343 - val_accuracy: 0.6373\n",
      "Epoch 43/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4890 - accuracy: 0.8610\n",
      "Epoch 43: val_accuracy improved from 0.63799 to 0.64080, saving model to final_model_weights.hdf5\n",
      "358/358 [==============================] - 212s 592ms/step - loss: 0.4890 - accuracy: 0.8610 - val_loss: 1.3673 - val_accuracy: 0.6408\n",
      "Epoch 44/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.8658\n",
      "Epoch 44: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 534s 1s/step - loss: 0.4773 - accuracy: 0.8658 - val_loss: 1.4844 - val_accuracy: 0.6282\n",
      "Epoch 45/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8686\n",
      "Epoch 45: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 780s 2s/step - loss: 0.4731 - accuracy: 0.8686 - val_loss: 1.4849 - val_accuracy: 0.6333\n",
      "Epoch 46/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8695\n",
      "Epoch 46: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 1309s 4s/step - loss: 0.4671 - accuracy: 0.8695 - val_loss: 1.4508 - val_accuracy: 0.6359\n",
      "Epoch 47/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8696\n",
      "Epoch 47: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 332s 920ms/step - loss: 0.4716 - accuracy: 0.8696 - val_loss: 1.4549 - val_accuracy: 0.6392\n",
      "Epoch 48/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8764\n",
      "Epoch 48: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 209s 585ms/step - loss: 0.4585 - accuracy: 0.8764 - val_loss: 1.4852 - val_accuracy: 0.6259\n",
      "Epoch 49/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.8765\n",
      "Epoch 49: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 211s 588ms/step - loss: 0.4534 - accuracy: 0.8765 - val_loss: 1.4767 - val_accuracy: 0.6329\n",
      "Epoch 50/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.8830\n",
      "Epoch 50: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 213s 596ms/step - loss: 0.4391 - accuracy: 0.8830 - val_loss: 1.4998 - val_accuracy: 0.6178\n",
      "Epoch 51/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8834\n",
      "Epoch 51: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 213s 595ms/step - loss: 0.4396 - accuracy: 0.8834 - val_loss: 1.5249 - val_accuracy: 0.6347\n",
      "Epoch 52/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8842\n",
      "Epoch 52: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 210s 585ms/step - loss: 0.4357 - accuracy: 0.8842 - val_loss: 1.5056 - val_accuracy: 0.6361\n",
      "Epoch 53/90\n",
      "358/358 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8844Restoring model weights from the end of the best epoch: 43.\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.64080\n",
      "358/358 [==============================] - 211s 588ms/step - loss: 0.4337 - accuracy: 0.8844 - val_loss: 1.5444 - val_accuracy: 0.6331\n",
      "Epoch 53: early stopping\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_data.n // training_data.batch_size\n",
    "validation_steps = validation_set.n // validation_set.batch_size\n",
    "\n",
    "history = model.fit(x=training_data,\n",
    "                 validation_data=validation_set,\n",
    "                 epochs=90,\n",
    "                 callbacks=[checkpointer],\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 15s 135ms/step - loss: 1.3757 - accuracy: 0.6366\n",
      "Test accuracy = 63.65792155265808%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy = {model.evaluate(test_data ,batch_size=test_data.batch_size,steps=test_data.n // test_data.batch_size)[1]*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Code for real time prediction ##\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class_names = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "model = tf.keras.models.load_model('final_model_weights.hdf5')\n",
    "\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "faceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceDetect.detectMultiScale(gray, 1.3, 3)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        sub_face_img = gray[y : y + h, x : x + w]\n",
    "        resized = cv2.resize(sub_face_img, (48, 48))\n",
    "        normalize = resized / 255.0\n",
    "        reshaped = np.reshape(normalize, (1, 48, 48, 1))\n",
    "        result = model.predict(reshaped)\n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "        print(label)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (50, 50, 255), 2)\n",
    "        cv2.rectangle(frame, (x, y - 40), (x + w, y), (50, 50, 255), -1)\n",
    "        cv2.putText(frame, class_names[label], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
